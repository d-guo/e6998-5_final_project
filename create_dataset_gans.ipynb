{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "575ae430",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle as pkl\n",
    "\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "from PIL import Image\n",
    "from torchvision.datasets import MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65f4111e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c44ac6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['image.cmap'] = 'Blues_r'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78901084",
   "metadata": {},
   "source": [
    "## Save to Training Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d26ec2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 10000\n",
    "data_dir = './gans_data/data_dg'\n",
    "MAX_DIGITS = 5\n",
    "\n",
    "with open('./data/MNIST_sep/num_per_class.pkl', 'rb') as f:\n",
    "    num_per_class = pkl.load(f)\n",
    "    \n",
    "# create directory to save training data\n",
    "if not os.path.exists(data_dir):\n",
    "    os.makedirs(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc3e9ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete existing data\n",
    "# shutil.rmtree(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "516a340e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_YOLO_sample(sample):\n",
    "    \"\"\"\n",
    "    sample: string of digits to create the sample\n",
    "        - ex. 194\n",
    "    returns numpy image and lists for classes and box annotations\n",
    "    \"\"\"\n",
    "    \n",
    "    images = []\n",
    "    classes = []\n",
    "    annotations = []\n",
    "    for idx, digit in enumerate(sample):\n",
    "        if digit == '_':\n",
    "            images.append(np.zeros((28, 28)))\n",
    "            continue\n",
    "        \n",
    "        image_to_stitch_idx = random.randint(0, num_per_class[int(digit)] - 1)\n",
    "        with open(f'./data/MNIST_sep/{digit}/{image_to_stitch_idx}.pkl', 'rb') as f:\n",
    "            image_to_stitch = pkl.load(f)\n",
    "        images.append(image_to_stitch)\n",
    "        \n",
    "        digit_class = float(digit)\n",
    "        x_coord = (idx + 0.5) / len(sample)\n",
    "        y_coord = 0.5\n",
    "        width = 0.9 / len(sample)\n",
    "        height = 0.9\n",
    "        \n",
    "        classes.append((digit_class))\n",
    "        annotations.append((x_coord, y_coord, width, height))\n",
    "    \n",
    "    image_np = np.concatenate(images, axis=1)\n",
    "    \n",
    "    return image_np, classes, annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "856e79da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate and save YOLO data and annotations\n",
    "\n",
    "image_list = []\n",
    "classes_list = []\n",
    "annotations_list = []\n",
    "\n",
    "for sample_num in range(num_samples):\n",
    "    sample = str(random.randint(1, int('9' * MAX_DIGITS)))\n",
    "    \n",
    "    # insert blanks randomly to front and back of sample to get same size samples\n",
    "    while len(sample) < MAX_DIGITS:\n",
    "        # use '_' to denote a blank\n",
    "        sample = '_' + sample if random.uniform(0, 1) < 0.5 else sample + '_'\n",
    "    \n",
    "    image_np, classes, annotations = create_YOLO_sample(sample)\n",
    "    \n",
    "    image_list.append(torch.tensor(image_np).unsqueeze(0).double())\n",
    "    classes_list.append(torch.tensor(classes).double())\n",
    "    annotations_list.append(torch.tensor(annotations).double())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "07a4c10e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "torch.Size([1, 28, 140])\n"
     ]
    }
   ],
   "source": [
    "print(len(image_list))\n",
    "print(image_list[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c427623e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "torch.Size([5])\n"
     ]
    }
   ],
   "source": [
    "print(len(classes_list))\n",
    "print(classes_list[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "85c2d934",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "torch.Size([5, 4])\n"
     ]
    }
   ],
   "source": [
    "print(len(annotations_list))\n",
    "print(annotations_list[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eb2537a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{data_dir}/image_list', 'wb+') as f:\n",
    "    pkl.dump(image_list, f)\n",
    "    \n",
    "with open(f'{data_dir}/classes_list', 'wb+') as f:\n",
    "    pkl.dump(classes_list, f)\n",
    "    \n",
    "with open(f'{data_dir}/annotations_list', 'wb+') as f:\n",
    "    pkl.dump(annotations_list, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9074d261",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
